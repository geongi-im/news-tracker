import os
from dotenv import load_dotenv
import feedparser
from datetime import datetime, timedelta
import re
from html import unescape
import time
import logging
import json
from deepseek_client import DeepSeekClient
from gemini_client import GeminiClient
from utils.api_util import ApiUtil, ApiError
from utils.logger_util import LoggerUtil
from utils.telegram_util import TelegramUtil

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê±° ì´ˆê¸°í™”
logger = LoggerUtil().get_logger()

def initialize_ai_client():
    """AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

    Returns:
        AI í´ë¼ì´ì–¸íŠ¸ ê°ì²´ (DeepSeekClient ë˜ëŠ” GeminiClient)

    Raises:
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” AI Providerì¸ ê²½ìš°
    """
    ai_provider = os.getenv('AI_PROVIDER')

    if ai_provider == 'deepseek':
        return DeepSeekClient(
            api_key=os.getenv('DEEPSEEK_API_KEY'),
            model_id=os.getenv('DEEPSEEK_MODEL')
        )
    elif ai_provider == 'gemini':
        return GeminiClient(
            api_key=os.getenv('GOOGLE_API_KEY'),
            model_id=os.getenv('GEMINI_MODEL')
        )
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” AI Provider: {ai_provider}")

def clean_html(raw_html):
    """HTML íƒœê·¸ ì œê±°"""
    # HTML íƒœê·¸ ì œê±°
    cleanr = re.compile('<.*?>')
    text = re.sub(cleanr, '', raw_html)
    # HTML ì—”í‹°í‹° ë””ì½”ë”© (ì˜ˆ: &quot; -> ", &amp; -> &)
    text = unescape(text)
    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = ' '.join(text.split())
    return text

def clean_text(text):
    """í…ìŠ¤íŠ¸ ì •ì œ"""
    if not text:
        return ''
    # HTML íƒœê·¸ ë° ì—”í‹°í‹° ì œê±°
    text = clean_html(text)
    # íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ (í•„ìš”í•œ ê²½ìš° ì¶”ê°€)
    text = text.replace('\n', ' ').replace('\r', '')
    return text.strip()

def is_within_24_hours(published_time):
    """ê¸°ì‚¬ê°€ 24ì‹œê°„ ì´ë‚´ì¸ì§€ í™•ì¸"""
    if not published_time:
        return False
        
    try:
        # í˜„ì¬ ì‹œê°„ê³¼ ê¸°ì‚¬ ë°œí–‰ ì‹œê°„ì˜ ì°¨ì´ ê³„ì‚°
        current_time = datetime.now()
        article_time = datetime(*published_time[:6])  # published_parsedëŠ” time.struct_time í˜•ì‹
        time_difference = current_time - article_time
        
        return time_difference.total_seconds() <= 24 * 60 * 60  # 24ì‹œê°„ì„ ì´ˆë¡œ ë³€í™˜
    except Exception as e:
        logger.error(f"ì‹œê°„ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def fetch_rss_feed(feed_url, api_util, feed_info):
    """RSS í”¼ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        feed = feedparser.parse(feed_url)

        # entriesê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        if hasattr(feed, 'entries'):
            # published_parsedë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹ ìˆœ ì •ë ¬
            feed.entries.sort(
                key=lambda x: x.get('published_parsed', time.gmtime(0)),
                reverse=True
            )

            # 1ë‹¨ê³„: 24ì‹œê°„ ì´ë‚´ + ì‚¬ì§„ ê¸°ì‚¬ ì•„ë‹Œ ê²ƒë§Œ í•„í„°ë§
            pre_filtered_entries = []
            for entry in feed.entries:
                # 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ í•„í„°ë§
                if not is_within_24_hours(entry.get('published_parsed')):
                    continue

                title = entry.title
                summary = entry.get('summary', '')

                # ì‚¬ì§„ ê¸°ì‚¬ í•„í„°ë§ (ì œëª©ì— 'í¬í† ' í¬í•¨ ë˜ëŠ” ë‚´ìš© ì—†ìŒ)
                if 'í¬í† ' in title or not summary.strip():
                    logger.debug(f"ì‚¬ì§„ ê¸°ì‚¬ ê±´ë„ˆëœ€: {title}")
                    continue

                pre_filtered_entries.append(entry)

            # 2ë‹¨ê³„: ë°°ì¹˜ë¡œ ì¤‘ë³µ ì²´í¬
            if pre_filtered_entries:
                urls = [entry.link for entry in pre_filtered_entries]
                logger.info(f"ë°°ì¹˜ ì¤‘ë³µ ì²´í¬ ì‹œì‘: {len(urls)}ê°œ URL")

                duplicate_results = api_util.is_news_exists_batch(urls)

                # ì¤‘ë³µë˜ì§€ ì•Šì€ ë‰´ìŠ¤ë§Œ ìµœì¢… í•„í„°ë§
                filtered_entries = []
                for entry in pre_filtered_entries:
                    if duplicate_results.get(entry.link, False):
                        logger.debug(f"ì¤‘ë³µëœ ë‰´ìŠ¤ ê±´ë„ˆëœ€: {entry.title}")
                        continue
                    filtered_entries.append(entry)

                logger.info(f"ì¤‘ë³µ ì²´í¬ ì™„ë£Œ: {len(filtered_entries)}/{len(pre_filtered_entries)}ê°œ ë‰´ìŠ¤ê°€ ìƒˆë¡œìš´ ë‰´ìŠ¤")
            else:
                filtered_entries = []

            feed.entries = filtered_entries

        return feed
    except Exception as e:
        logger.error(f"RSS í”¼ë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None

def main():
    logger.info("RSS ë‰´ìŠ¤ ìˆ˜ì§‘ í”„ë¡œê·¸ë¨ ì‹œì‘")

    # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì²´í¬
    required_env_vars = [
        "AI_PROVIDER",
        "BASE_URL",
        "TELEGRAM_CHAT_TEST_ID",
        "TELEGRAM_CHAT_ID",
        "TELEGRAM_BOT_TOKEN"
    ]

    missing_vars = []
    for var in required_env_vars:
        if not os.getenv(var):
            missing_vars.append(var)

    if missing_vars:
        error_message = f"ğŸ›‘ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}"
        logger.error(error_message)
        raise ValueError(error_message)
    else:
        ai_provider = os.getenv('AI_PROVIDER')
        telegram_util = TelegramUtil()
        api_util = ApiUtil()

    # ì„ íƒ í™˜ê²½ë³€ìˆ˜ ì²´í¬
    if ai_provider not in ['deepseek', 'gemini']:
        error_message = f"AI_PROVIDER ê°’ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {ai_provider} (deepseek ë˜ëŠ” geminië§Œ ê°€ëŠ¥)"
        logger.error(error_message)
        raise ValueError(error_message)
    
    # AI Providerë³„ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    if ai_provider == 'deepseek':
        DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
        DEEPSEEK_MODEL = os.getenv('DEEPSEEK_MODEL')
        if not DEEPSEEK_API_KEY:
            error_message = "DEEPSEEK_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            logger.error(error_message)
            raise ValueError(error_message)
        if not DEEPSEEK_MODEL:
            error_message = "DEEPSEEK_MODELì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì˜ˆ: deepseek-chat)"
            logger.error(error_message)
            raise ValueError(error_message)
    elif ai_provider == 'gemini':
        GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
        GEMINI_MODEL = os.getenv('GEMINI_MODEL')
        if not GOOGLE_API_KEY:
            error_message = "GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            logger.error(error_message)
            raise ValueError(error_message)
        if not GEMINI_MODEL:
            error_message = "GEMINI_MODELì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì˜ˆ: gemini-flash-lite-latest)"
            logger.error(error_message)
            raise ValueError(error_message)


    # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        ai_client = initialize_ai_client()
        logger.info(f"AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {ai_provider}")
    except Exception as e:
        logger.error(f"AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        telegram_util.send_test_message(f"[news-tracker] ğŸš¨ AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return

    # RSS í”¼ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    try:
        # í™œì„±í™”ëœ RSS í”¼ë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        active_feeds = api_util.get_active_rss_feeds()
        logger.info(f"í™œì„±í™”ëœ RSS í”¼ë“œ ìˆ˜: {len(active_feeds)}")
        
        # ê° RSS í”¼ë“œ ì²˜ë¦¬
        for feed_info in active_feeds:
            logger.info(f"Processing feed: {feed_info['mq_company']} - {feed_info['mq_category']}")

            rss_data = fetch_rss_feed(feed_info['mq_rss'], api_util, feed_info)
            
            if rss_data and hasattr(rss_data, 'entries'):
                logger.info(f"Found {len(rss_data.entries)} valid entries from {feed_info['mq_company']}")
                
                # ê° ë‰´ìŠ¤ í•­ëª© ì²˜ë¦¬
                for entry in rss_data.entries:
                    title = entry.title
                    published_date = time.localtime(time.mktime(entry.get('published_parsed', time.gmtime(0))) + 9 * 3600)
                    summary = entry.get('summary', '')
                    summary = clean_html(summary)  # HTML íƒœê·¸ ë° ì—”í‹°í‹° ì œê±°

                    # AI ëª¨ë¸ë¡œ ë‰´ìŠ¤ ë¶„ì„
                    analysis_result = ai_client.get_response(
                        input_data={
                            'category': feed_info['mq_category'],
                            'title': title,
                            'summary': summary
                        },
                        prompt_path='step1_prompt.md'
                    )
                    
                    if analysis_result and analysis_result.parsed_data:
                        logger.info(f"ì œëª©: {title[:30]}... | ë¶„ì„ ê²°ê³¼: {analysis_result.parsed_data}")

                        if int(analysis_result.parsed_data['total_score']) >= 8:
                            api_util.insert_news({
                                'category': feed_info['mq_category'],
                                'title': title,
                                'content': summary,
                                'company': feed_info['mq_company'],
                                'source_url': entry.link,
                                'published': published_date,
                                'step1_score': analysis_result.parsed_data['total_score']
                            })
            else:
                logger.error(f"Failed to fetch RSS feed: {feed_info['mq_rss']}")

    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        telegram_util.send_test_message(f"[news-tracker] ğŸš¨ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")

    logger.info("RSS ë‰´ìŠ¤ ìˆ˜ì§‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    main()
